# Fine-tuning FLAN-T5 para Mapeamento TÃ­tuloâ†’DescriÃ§Ã£o

## ğŸ¯ DescriÃ§Ã£o

Este projeto implementa fine-tuning do modelo FLAN-T5 para mapear perguntas sobre tÃ­tulos de produtos para suas respectivas descriÃ§Ãµes.

## ğŸš€ Funcionalidades

- **Carregamento e limpeza** de dados JSON
- **Fine-tuning** do modelo google/flan-t5-base
- **GeraÃ§Ã£o de pares** perguntaâ†’resposta
- **AvaliaÃ§Ã£o** com mÃ©trica ROUGE
- **DemonstraÃ§Ã£o** de inferÃªncia

## ğŸ“Š Dataset

- **Fonte:** trn.json (Amazon Titles)
- **Formato:** JSON Lines
- **Colunas:** title, content
- **Tamanho:** ~2.2M registros

## ğŸ› ï¸ Tecnologias

- **Python 3.12**
- **Transformers 4.55.2**
- **PyTorch**
- **Pandas**
- **Datasets (Hugging Face)**

## ğŸ“ Estrutura

```
fine-tuning/
â”œâ”€â”€ tech_challenge_train.py    # Script principal
â”œâ”€â”€ data/                      # Dados de treinamento
â”œâ”€â”€ outputs/                   # Modelo treinado
â””â”€â”€ README.md
```

## ğŸš€ Como Usar

### 1. Instalar DependÃªncias
```bash
pip install -r requirements.txt
```

### 2. Executar Treinamento
```bash
python tech_challenge_train.py
```

### 3. Testar Modelo
O script inclui demonstraÃ§Ã£o automÃ¡tica apÃ³s o treinamento.

## âš™ï¸ ConfiguraÃ§Ãµes

- **Modelo Base:** google/flan-t5-base
- **Ã‰pocas:** 2
- **Batch Size:** 4
- **Learning Rate:** 3e-4
- **Max Input Length:** 512 tokens
- **Max Target Length:** 256 tokens

## ğŸ“ˆ MÃ©tricas

- **ROUGE-L** para avaliaÃ§Ã£o de qualidade
- **Loss** durante treinamento
- **Gradiente norm** para estabilidade

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.

